{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f24edbd-9e0d-47e5-bb76-26bc8f6cf895",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, BooleanType, MapType, DoubleType, LongType\n",
    "\n",
    "class BronzeLayer:\n",
    "    def __init__(self):\n",
    "        self.raw_data_dir = \"/mnt/raw_data\"\n",
    "        self.checkpoint_dir = \"/mnt/raw_data/checkpoint/bronze\"\n",
    "\n",
    "    def get_schema(self):\n",
    "        return StructType([\n",
    "            StructField(\"base\", StringType(), True),\n",
    "            StructField(\"date\", StringType(), True),\n",
    "            StructField(\"historical\", BooleanType(), True),\n",
    "            StructField(\"rates\", MapType(StringType(), DoubleType()), True),\n",
    "            StructField(\"success\", BooleanType(), True),\n",
    "            StructField(\"timestamp\", LongType(), True),\n",
    "        ])\n",
    "\n",
    "    def process_stream(self):\n",
    "        bronzeDF = (spark.readStream\n",
    "                        .format(\"json\")\n",
    "                        .schema(self.get_schema())\n",
    "                        .load(\"/mnt/raw_data\"))\n",
    "\n",
    "        query = (bronzeDF.writeStream\n",
    "                  .format(\"delta\")\n",
    "                  .outputMode(\"append\")\n",
    "                  .option(\"checkpointLocation\", \"/mnt/raw_data/checkpoint/bronze_checkpoint\")\n",
    "                  .trigger(availableNow=True)\n",
    "                  .toTable(\"fixer_bronze\"))\n",
    "\n",
    "        return query\n",
    "\n",
    "# Start the Bronze stream\n",
    "bronze_layer = BronzeLayer()\n",
    "bronze_query = bronze_layer.process_stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "896f607f-8810-42d4-8ab4-00ae7facf830",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "class SilverLayer:\n",
    "    def process_stream(self):\n",
    "        bronzeDF = spark.readStream.table(\"fixer_bronze\")\n",
    "\n",
    "        explodedDF = bronzeDF.selectExpr(\n",
    "            \"date\",\n",
    "            \"timestamp as modify_time\",\n",
    "            \"explode(rates) as (currency, rate)\"\n",
    "        )\n",
    "\n",
    "        query = (explodedDF.writeStream\n",
    "                            .format(\"delta\")\n",
    "                            .option(\"checkpointLocation\", \"/mnt/raw_data/checkpoint/silver_checkpoint\")\n",
    "                            .outputMode(\"append\")\n",
    "                            .trigger(availableNow=True)\n",
    "                            .toTable(\"fixer_silver\"))\n",
    "        return query\n",
    "\n",
    "# Start the Silver stream\n",
    "silver_layer = SilverLayer()\n",
    "silver_query = silver_layer.process_stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "241afe1c-a308-4e89-a446-a6743b8ae2d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import from_unixtime, col\n",
    "\n",
    "class GoldLayer:\n",
    "    def __init__(self):\n",
    "        self.silver_table = \"fixer_silver\"\n",
    "        self.gold_table = \"fixer_gold\"\n",
    "        self.checkpoint_location = \"/mnt/raw_data/checkpoint/gold_checkpoint\"\n",
    "\n",
    "    def pivotDF(self, silverDF):\n",
    "        silverDF_with_event_time = silverDF.withColumn(\n",
    "            \"event_time\", from_unixtime(col(\"modify_time\")).cast(\"timestamp\")\n",
    "        )\n",
    "\n",
    "        pivotedDF = (\n",
    "            silverDF_with_event_time\n",
    "                .withWatermark(\"event_time\", \"7 days\")\n",
    "                .groupBy(\"date\", \"event_time\")\n",
    "                .pivot(\"currency\", [\"USD\", \"JPY\", \"CNY\"])\n",
    "                .agg({\"rate\": \"first\"})\n",
    "        )\n",
    "\n",
    "        return pivotedDF\n",
    "\n",
    "    def upsert_to_delta(self, batchDF, batchId):\n",
    "        try:\n",
    "            batchDF.createOrReplaceTempView(\"gold_updates\")\n",
    "\n",
    "            spark.sql(f\"\"\"\n",
    "                MERGE INTO {self.gold_table} tgt\n",
    "                USING gold_updates src\n",
    "                ON tgt.date = src.date AND tgt.event_time = src.event_time\n",
    "                WHEN MATCHED THEN UPDATE SET *\n",
    "                WHEN NOT MATCHED THEN INSERT *\n",
    "            \"\"\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error in batchId {batchId}: {str(e)}\")\n",
    "        else:\n",
    "            print(f\"✅ Batch {batchId} successfully merged into {self.gold_table}\")\n",
    "\n",
    "    def process_stream(self):\n",
    "        silverDF = spark.readStream.table(self.silver_table)\n",
    "        pivotedDF = self.pivotDF(silverDF)\n",
    "\n",
    "        query = (\n",
    "            pivotedDF.writeStream\n",
    "                .queryName(\"gold-processing\")\n",
    "                .foreachBatch(self.upsert_to_delta)\n",
    "                .option(\"checkpointLocation\", \"/mnt/raw_data/checkpoint/gold_checkpoint\")\n",
    "                .outputMode(\"append\")\n",
    "                .trigger(availableNow=True)\n",
    "                .start()\n",
    "        )\n",
    "\n",
    "        return query\n",
    "\n",
    "    def upsert_to_delta(self, batchDF, batchId):\n",
    "        try:\n",
    "            batchDF.createOrReplaceTempView(\"gold_updates\")\n",
    "\n",
    "            spark.sql(f\"\"\"\n",
    "                MERGE INTO {self.gold_table} tgt\n",
    "                USING gold_updates src\n",
    "                ON tgt.date = src.date AND tgt.event_time = src.event_time\n",
    "                WHEN MATCHED THEN UPDATE SET *\n",
    "                WHEN NOT MATCHED THEN INSERT *\n",
    "            \"\"\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Batch {batchId} error: {str(e)}\")\n",
    "        else:\n",
    "            print(f\"✅ Batch {batchId} upsert completed successfully.\")\n",
    "\n",
    "# Make sure fixer_gold exists once initially before running streaming\n",
    "silverDF = spark.table(\"fixer_silver\")\n",
    "pivotedDF = (\n",
    "    silverDF.withColumn(\"event_time\", from_unixtime(col(\"modify_time\")).cast(\"timestamp\"))\n",
    "            .groupBy(\"date\", \"event_time\")\n",
    "            .pivot(\"currency\", [\"USD\", \"JPY\", \"CNY\"])\n",
    "            .agg({\"rate\": \"first\"})\n",
    ")\n",
    "\n",
    "pivotedDF.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"overwriteSchema\", \"true\") \\\n",
    "    .saveAsTable(\"fixer_gold\")\n",
    "\n",
    "\n",
    "# Start streaming job\n",
    "gold_layer = GoldLayer()\n",
    "gold_query = gold_layer.process_stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f9db199-903c-405e-970e-5035ba96e317",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>date</th><th>event_time</th><th>USD</th><th>JPY</th><th>CNY</th></tr></thead><tbody><tr><td>2025-02-19</td><td>2025-02-19T23:59:59Z</td><td>0.634009</td><td>95.877343</td><td>4.617962</td></tr><tr><td>2025-02-20</td><td>2025-02-20T23:59:59Z</td><td>0.6402</td><td>95.653931</td><td>4.645307</td></tr><tr><td>2025-02-21</td><td>2025-02-21T23:59:59Z</td><td>0.6355</td><td>94.832503</td><td>4.608036</td></tr><tr><td>2025-02-24</td><td>2025-02-24T23:59:59Z</td><td>0.63376</td><td>94.981535</td><td>4.593554</td></tr><tr><td>2025-02-22</td><td>2025-02-22T23:59:59Z</td><td>0.6357</td><td>94.868705</td><td>4.609486</td></tr><tr><td>2025-02-26</td><td>2025-02-26T23:59:59Z</td><td>0.631028</td><td>93.923827</td><td>4.591453</td></tr><tr><td>2025-02-23</td><td>2025-02-23T23:59:59Z</td><td>0.636981</td><td>95.140164</td><td>4.618766</td></tr><tr><td>2025-02-25</td><td>2025-02-25T23:59:59Z</td><td>0.635169</td><td>94.685545</td><td>4.603767</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "2025-02-19",
         "2025-02-19T23:59:59Z",
         0.634009,
         95.877343,
         4.617962
        ],
        [
         "2025-02-20",
         "2025-02-20T23:59:59Z",
         0.6402,
         95.653931,
         4.645307
        ],
        [
         "2025-02-21",
         "2025-02-21T23:59:59Z",
         0.6355,
         94.832503,
         4.608036
        ],
        [
         "2025-02-24",
         "2025-02-24T23:59:59Z",
         0.63376,
         94.981535,
         4.593554
        ],
        [
         "2025-02-22",
         "2025-02-22T23:59:59Z",
         0.6357,
         94.868705,
         4.609486
        ],
        [
         "2025-02-26",
         "2025-02-26T23:59:59Z",
         0.631028,
         93.923827,
         4.591453
        ],
        [
         "2025-02-23",
         "2025-02-23T23:59:59Z",
         0.636981,
         95.140164,
         4.618766
        ],
        [
         "2025-02-25",
         "2025-02-25T23:59:59Z",
         0.635169,
         94.685545,
         4.603767
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "dataframeName": "_sqldf",
        "executionCount": 39
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "date",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "event_time",
         "type": "\"timestamp\""
        },
        {
         "metadata": "{}",
         "name": "USD",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "JPY",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "CNY",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "select * from fixer_gold where date >= \"2025-02-19\""
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 894510466120176,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "4_streaming_blonze_silver_gold",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
